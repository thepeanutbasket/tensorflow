{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02-HelloTensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow 모듈 import\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'\\xec\\x95\\x88\\xeb\\x85\\x95, \\xed\\x85\\x90\\xec\\x84\\x9c\\xed\\x94\\x8c\\xeb\\xa1\\x9c\\xec\\x9a\\xb0 !'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# constant() 함수를 사용하여 출력할 메시지를 텐서플로우에 입력\n",
    "hello = tf.constant('안녕, 텐서플로우 !')\n",
    "\n",
    "# hello 객체는 텐서플로우 자체를 가리키게 된다.\n",
    "# 텐서가 실행되기 전까지는 tf.constant() 함수로 입력한 문자열이 출력되지 않는다.\n",
    "# tensorflow는 변수라는 개념이 없다. 그래서 출력하면 아래 출력값처럼 tensorflow 객체가 나온다.\n",
    "hello"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. tf1 버전의 Hello World"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(), dtype=string)\n",
      "안녕, 텐서플로우 !\n"
     ]
    }
   ],
   "source": [
    "# 세션(텐서플로우 실행기) 객체 생성\n",
    "# tf1에서 사용하던 기능은 compat.v1 객체 안에 포함되어 있다. -> tf1에서 사용하던 기능을 tf2(현재 사용버전)에서 사용하고 싶을 때 compat.v1을 적으면 된다.\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    hello = tf.constant('안녕, 텐서플로우 !')\n",
    "    \n",
    "    print(hello)\n",
    "    \n",
    "    # 세션 실행\n",
    "    k = sess.run(hello)\n",
    "    \n",
    "    # 실행 결과를 UTF-8로 디코딩 해줘야 한다.\n",
    "    r = k.decode('utf-8')\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(r)\n",
    "    \n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 세션을 실행하기 전까지는 그 무엇도 실행되지 않는다. \n",
    "* 위의 코드가 2.x버전에서 실행하는 tensorflow 1.x의 코드라고 생각하면 된다. 객체 안에 한국어가 들어있는 경우에는 UTF-8로 디코딩해주어야 문제없이 출력할 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. tf2 버전의 Hello World\n",
    "\n",
    "* tf1버전과 비교해보면 훨씬 짧은 것을 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕, 텐서플로우 !\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "msg = tf.constant('안녕, 텐서플로우 !')\n",
    "tf.print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. 텐서의 이해\n",
    "\n",
    "## 1) 텐서(Tensor) 플로우(Flow)\n",
    "\n",
    "텐서(Tensor)들을 흘려 보내면서(Flow) 데이터를 처리하는 라이브러리.\n",
    "\n",
    "## 2) 용어 정리\n",
    "\n",
    "- 텐서(Tensor) : 다차원배열\n",
    "- 랭크(Rank) : 텐서의 차원(Dimension). numpy 배열의 shape 값으로 확인 가능\n",
    "\n",
    "일반적으로 텐서라 함은 Rank가 3인 배열(3차원 배열)\n",
    "\n",
    "- 스칼라: Rank가 0인 텐서\n",
    "- 벡터: Rank가 1인 텐서\n",
    "- 행렬: Rank가 2인 텐서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(100)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 랭크가 0인 배열 --> 스칼라(값)\n",
    "a = 100\n",
    "ts1 = np.array(a)\n",
    "print(ts1.shape)   # 차원(행,렬)을 보여줌\n",
    "ts1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 랭크가 1인 배열 --> 백터(Vector)\n",
    "b = [1, 2, 3]\n",
    "ts2 = np.array(b)\n",
    "print(ts2.shape)\n",
    "ts2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 10,  20,  30],\n",
       "       [100, 200, 300]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 랭크가 2인 배열 --> 행렬(Matrix)\n",
    "c = [ [10,20,30], [100,200,300]]\n",
    "ts3 = np.array(c)\n",
    "print(ts3.shape)\n",
    "ts3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[-1, -2, -3],\n",
       "        [ 1,  2,  3]],\n",
       "\n",
       "       [[-1,  0,  1],\n",
       "        [ 1,  0, -1]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 랭크가 3인 배열 --> 텐서(Tensor)\n",
    "d = [ [ [-1, -2, -3], [1, 2, 3] ], [ [-1, 0, 1], [1, 0, -1] ] ]\n",
    "ts4 = np.array(d)\n",
    "print(ts4.shape)\n",
    "ts4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 텐서플로우의 덧셈뺄셈은 이진구조로 이루어진다...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. 계산 그래프 (Computational Graph)\n",
    "\n",
    "## 1) 계산 그래프의 의미\n",
    "\n",
    "컴퓨터 공학에서 정의하는 노드(Node)와 엣지(Edge)로 이루어진 자료구조.\n",
    "\n",
    "<이미지>\n",
    "\n",
    "각각의 노드에 연산자나 숫자 등을 넣을 수 있다.\n",
    "텐서들이 계산 그래프 구조를 통해 노드에서 노드로 이동한다.\n",
    "\n",
    "텐서플로우 라이브러리는 그래프 구조를 먼저 정의하고 정의한 그래프에 실제 텐서들을 흘려보내도록 디자인되었다.\n",
    "\n",
    "## 2) 텐서플로우 프로그램의 작성 과정\n",
    "\n",
    "### 그래프 생성\n",
    "\n",
    "노드에 연산, 변수, 상수 등을 정의하여 연산 과정을 그래프로 표현한다.\n",
    "\n",
    "### 그래프 실행\n",
    "\n",
    "노드간의 연결인 엣지를 통해 텐서를 주고 받으면서 계산을 수행한다.\n",
    "\n",
    "## 3) 상수 선언하기\n",
    "\n",
    "```python\n",
    "node = tf.constant(value, dtype = None, shape = None, name = 'Const')\n",
    "```\n",
    "\n",
    "- value : 상수값. 직접 지정하거나 shape 형태(Python의 list 구조)로 채울 ㄱ밧을 지정할 수 있다.\n",
    "- dtype : 데이터 타입 (ex: tf.float32, tf.int32, tf.bool)\n",
    "- shape : 상수 데이터의 형태 (배열의 차원)\n",
    "- name : 텐서의 이름\n",
    "\n",
    "## 4) 상수 텐서를 정의하고 덧셈 결과 출력하기\n",
    "\n",
    "### TF2 버전으로 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=3.0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 그래프 노드를 정의하고 출력\n",
    "# -> 노드의 정보만 출력될 뿐 실제 값이 출력되지는 않는다.\n",
    "# python에서 보면 hello = 3.0\n",
    "node1 = tf.constant(3.0, dtype = tf.float32, name = 'hello')\n",
    "node1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=4.0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 암시적으로 타입 지정하기 --> tf.float32 타입으로 선언된다.\n",
    "# python에서 보면 world = 4.0\n",
    "node2 = tf.constant(4.0, name = 'world')\n",
    "node2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=7.0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 두 개의 노드의 값을 더하는 연산을 수행하는 node3을 정의\n",
    "# -> 'node3 = node1 + node2'와 같이 정의해도 같은 결과이다.\n",
    "# python에서 보면 hello + world\n",
    "node3 = tf.add(node1, node2)\n",
    "node3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "tf.print(node1)\n",
    "tf.print(node2)\n",
    "tf.print(node3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF1 버전으로 구현하기\n",
    "\n",
    "TF1에서는 항상 session을 생성해주어야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n",
      "4.0\n",
      "7.0\n",
      "[3.0, 4.0, 7.0]\n"
     ]
    }
   ],
   "source": [
    "with tf.compat.v1.Session() as sess:\n",
    "    node1 = tf.constant(3.0, dtype = tf.float32, name = 'hello')\n",
    "    node2 = tf.constant(4.0, name = 'world')\n",
    "    node3 = tf.add(node1, node2)\n",
    "    print(sess.run(node1))\n",
    "    print(sess.run(node2))\n",
    "    print(sess.run(node3))\n",
    "    \n",
    "    # 그래프 전체 실행\n",
    "    print(sess.run([node1, node2, node3]))\n",
    "    \n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05. 텐서보드(Tensorboard)\n",
    "학습 과정을 기록하고 기록된 결과를 시각화해서 보여주는 도구.\n",
    "텐서플로우의 계산식을 시각화시켜주는 것\n",
    "\n",
    "텐서플로우가 생성하는 계산 그래프를 시각화해서 볼 수 있기 때문에 실행 흐름을 이해하는데 도움이 된다.\n",
    "\n",
    "## 1) 주요 사용 방법\n",
    "\n",
    "### 요약 정도 생성하기\n",
    "\n",
    "세션이 실행할 계산 그래프가 저장될 폴더를 지정하여 기록 객체 만들기\n",
    "\n",
    "```python\n",
    "writer = tf.summary.FileWriter('폴더경로', 세션객체.graph)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/201121\n",
      "3.0\n",
      "4.0\n",
      "7.0\n",
      "[3.0, 4.0, 7.0]\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "logdir = 'logs/' + dt.datetime.now().strftime('%y%m%d')\n",
    "print(logdir)\n",
    "# logdir에 내가 주피터랩을 오픈한 폴더 속 새로운 폴더명을 입력하여 로그가 저장될 주소를 지정한다.\n",
    "# 확인해보면 폴더 안에 logs 폴더가 새로 생성되어 있음\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    writer = tf.compat.v1.summary.FileWriter(logdir, sess.graph)\n",
    "    # 여기서부터 모든 로그의 기록이 시작된다. writer를 열어줌.\n",
    "    \n",
    "    node1 = tf.constant(3.0, dtype = tf.float32, name = 'hello')\n",
    "    node2 = tf.constant(4.0, name = 'world')\n",
    "    node3 = tf.add(node1, node2)\n",
    "    print(sess.run(node1))\n",
    "    print(sess.run(node2))\n",
    "    print(sess.run(node3))\n",
    "    \n",
    "    # 그래프 전체 실행\n",
    "    print(sess.run([node1, node2, node3]))\n",
    "    \n",
    "    #기록 종료\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 여기서 명령 프롬프트를 하나 더 오픈한다.\n",
    "\n",
    "```shell\n",
    "tensorboard --logdir=./logs/201121 --port=9901      # 임의의 숫자 4개\n",
    "```\n",
    "\n",
    "마지막에 나오는 주소를 웹브라우저에 실행시킨다. 여기에선 http://localhost:9901/ 가 나온다. 그러면 tensorboard라는 새로운 창이 생성된다.\n",
    "그럼 그 창에 위에서 실행한 sess의 실행 결과가 노드와 글자로 구성되어 나타난다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06. 변수\n",
    "\n",
    "Variable()이라는 함수를 사용해서 변수를 만들 수 있다.\n",
    "\n",
    "## 1) 암묵적 데이터 타입 지정\n",
    "\n",
    "변수가 생성되는 순간에 데이터의 타입과 크기가 결정된다.\n",
    "\n",
    "\n",
    "### tf2 버전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=123>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable(123)\n",
    "x     # x라고만 하면 tensorflow 객체만 출력된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n"
     ]
    }
   ],
   "source": [
    "tf.print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223\n"
     ]
    }
   ],
   "source": [
    "y = tf.Variable(x + 100)\n",
    "tf.print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf1 버전\n",
    "\n",
    "지정된 변수를 초기화하기 위해 `initialize_all_variables()` 라는 함수를 반드시 먼저 호출한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\ezen\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:247: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "123\n"
     ]
    }
   ],
   "source": [
    "with tf.compat.v1.Session() as sess:\n",
    "    # 변수를 만들기 위한 노드\n",
    "    x = tf.compat.v1.Variable(123)\n",
    "    \n",
    "    # 변수를 초기화하기 위한 노드\n",
    "    init_op = tf.compat.v1.initialize_all_variables()\n",
    "    sess.run(init_op)     # 초기화 노드를 먼저 실행\n",
    "    value = sess.run(x)   # 변수 생성\n",
    "    print(value)          # 생성된 값 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) 명시적 타입 지정\n",
    "\n",
    "`dtype` 파라미터를 사용한다. 지정된 타입과 다른 형태의 스칼라가 명시될 경우 에러. (가급적 암시적 타입 지정을 사용하는 것이 더 낫다)\n",
    "\n",
    "> 구글에서 tf.dtypes.DType 으로 검색한 결과 참조 --> tensorflow에서 사용하는 데이터 타입이 정리되어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(123, dtype = tf.int32)\n",
    "tf.print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07. 난수\n",
    "\n",
    "## 1) 균등분포 난수\n",
    "\n",
    "일반적으로 각 이벤트의 결과값을 알 수 없는 경우 미래에 발생할 이벤트의 결과값 x가 예상되는 범위 안에서 균등한 확률로 일어날 것이라고 예측될 때 사용한다.\n",
    "\n",
    "미래 결과값이 경험적으로 알 수 없을 상황에서 사용한다.\n",
    "\n",
    "### 균등분포 난수의 예 - 주사위에 대한 확률\n",
    "\n",
    "- 200번을 던지고 201번째 주사위를 던진다고 했을 때 201번째 결과값은 앞의 1에서 200번까지의 결과값에 영향을 받지 않는다.\n",
    "- 201번째 결과값이 1,2,3,4,5,6 각각의 결과값으로 나올 확률은 6분의 1이며, 이는 앞의 1~200번째 결과값에 영향을 받아 줄어들거나 늘어나지 않는다는 것이다.\n",
    "\n",
    "> tf1에서는 `tf.random_uniform()` 함수 사용. 파라미터는 동일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n"
     ]
    }
   ],
   "source": [
    "# 스칼라 형태의 균등분포 난수\n",
    "rnd1 = tf.random.uniform(shape = [], minval = 0, maxval = 100, dtype = tf.int32)\n",
    "tf.print(rnd1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 67 59 47 74]\n"
     ]
    }
   ],
   "source": [
    "# 벡터 형태의 균등분포 난수\n",
    "# 생성되는 리스트의 원소는 각각 연관이 없다.\n",
    "rnd2 = tf.random.uniform(shape = [5], minval = 0, maxval = 100, dtype = tf.int32)\n",
    "tf.print(rnd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[46 62 41]\n",
      " [31 22 95]]\n"
     ]
    }
   ],
   "source": [
    "# 행렬 형태의 균등분포 난수\n",
    "rnd2 = tf.random.uniform(shape = [2,3], minval = 0, maxval = 100, dtype = tf.int32)\n",
    "tf.print(rnd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[89 90 76 54]\n",
      "  [4 67 21 66]\n",
      "  [10 58 95 84]]\n",
      "\n",
      " [[85 87 67 41]\n",
      "  [2 39 8 38]\n",
      "  [42 28 69 81]]]\n"
     ]
    }
   ],
   "source": [
    "# 텐서 형태의 균등분포 난수: tensor는 3차원 형태의 값\n",
    "rnd2 = tf.random.uniform(shape = [2,3,4], minval = 0, maxval = 100, dtype = tf.int32)\n",
    "tf.print(rnd2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) 정규분포 난수\n",
    "\n",
    "과거의 축적된 경험적 데이터를 이미 보유하고 있어 이를 이용하여 미래에 발생할 결과값 x의 각 예상되는 벌위별로 발생될 확률을 어느정도 추정할 수 있을 때 사용\n",
    "\n",
    "텐서에서는 과거의 경험에 대한 평균과 표준편차를 '직접' 지정하여 그에대한 정규분포값을 산정한다.\n",
    "\n",
    "### 정규분포 난수의 예 - 매장의 매출액 예측\n",
    "\n",
    "- 이전 3개월의 매출이 2천만원, 2천백만원, 2천2백만원 발생한 경우 평균이나 범위에 대한 예측이 가능하다.\n",
    "- 평균에 대한 예측 : 이번 달 매출은 과거 3개월의 매출 평균인 2천백만원으로 예측.\n",
    "- 범위에 대한 예측 : 최소 2천만원 ~ 최대 2천2백만원까지 매출이 발생할 수 있다는 예상이 가능함.\n",
    "\n",
    "### 참고\n",
    "\n",
    "- 편차(deviation) : 관측값에서 평균 또는 중앙값을 뺀 값\n",
    "- 분산(variance) : 관측값에서 평균을 뺀 값을 제곱하고, 그것을 모두 더한 후 전체 개수로 나눈 값(=차이값의 제곱의 평균). 관측값에서 평균을 뺀 값인 편차를 모두 더하면 0이 나오므로 제곱해서 더한다.\n",
    "- 표준편차(standard deviation) : 분산의 제곱근. 제곱해서 값이 부풀려진 분산을 제곱근해서 다시 원래 크기로 만들어준 상태."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.982854903\n"
     ]
    }
   ],
   "source": [
    "# 스칼라 형태의 정규분포 난수 -> 평균과 표준편차를 지정해준다.\n",
    "normal_rnd1 = tf.random.normal(shape = [], mean = 0.0, stddev = 1.0)\n",
    "tf.print(normal_rnd1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.511626959 -0.445747048 0.714480519 -0.713507175 1.31704235]\n"
     ]
    }
   ],
   "source": [
    "# 벡터 형태의 정규분포 난수\n",
    "normal_rnd2 = tf.random.normal(shape = [5], mean = 0.0, stddev = 1.0)\n",
    "tf.print(uni_rnd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.12223744 -0.468763322 0.565362096]\n",
      " [-1.86115932 -1.06715977 1.93411148]]\n"
     ]
    }
   ],
   "source": [
    "# 행렬 형태의 정규분포 난수\n",
    "normal_rnd3 = tf.random.normal(shape = [2,3], mean = 0.0, stddev = 1.0)\n",
    "tf.print(normal_rnd3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) 랜덤값을 갖는 행렬곱 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.80239141]\n",
      " [0.431075126]\n",
      " [0.271013856]]\n"
     ]
    }
   ],
   "source": [
    "# 랜덤값을 갖는 3행 2열의 행렬을 변수 x로 정의\n",
    "# random.uniform의 파라미터 기본값? minval = 0, maxval = 1, dtype = tf.float32\n",
    "x = tf.Variable(tf.random.uniform([3,2]))\n",
    "\n",
    "# 랜덤값을 갖는 2행 1열의 행렬을 변수 y로 정의\n",
    "y = tf.Variable(tf.random.uniform([2,1]))\n",
    "\n",
    "# 행렬곱에 대한 연산을 수행하는 노드 정의\n",
    "expr = tf.matmul(x,y)   # matrix multiply\n",
    "tf.print(expr)\n",
    "# 여기선 [3,2] * [2,1]이므로 결과값은 [3,1] 즉 3행 1열이 된다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
